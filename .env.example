# ROCm GPU Architecture Override
# For Strix Halo (RDNA 3.5), use 11.0.0
HSA_OVERRIDE_GFX_VERSION=11.5.1

# Whisper Configuration
# tiny.en, tiny, base.en, base, small.en, small, medium.en, medium,
# large-v1, large-v2, large-v3, large, distil-large-v2, distil-medium.en,
# distil-small.en, distil-large-v3, distil-large-v3.5, large-v3-turbo, turbo
WHISPER_MODEL=large-v3-turbo
WHISPER_COMPUTE_TYPE=float16
WHISPER_BEAM_SIZE=0
WHISPER_DEBUG=false

# Piper TTS Configuration (Commented out - migrated to Qwen3-TTS)
# Available voices: https://github.com/rhasspy/piper/blob/master/VOICES.md
# PIPER_VOICE=en_US-lessac-medium
# PIPER_LENGTH_SCALE=1.0
# PIPER_NOISE_SCALE=0.667
# PIPER_NOISE_W=0.8
# PIPER_DEBUG=false

# Qwen3-TTS VoiceDesign Configuration
# Model options:
#   Qwen/Qwen3-TTS-12Hz-1.7B-VoiceDesign - Larger, higher quality (text-based voice descriptions)
#   Qwen/Qwen3-TTS-12Hz-0.6B-Base - Smaller, faster (requires reference audio, not text descriptions)
QWEN_MODEL=Qwen/Qwen3-TTS-12Hz-1.7B-VoiceDesign
# Voice instruction examples:
#   "Young female voice with high pitch and energetic tone"
#   "Deep male voice with slow speaking rate and calm demeanor"
#   "Speak in an incredulous tone with hint of panic"
#   "Clear, natural voice with medium pitch"
QWEN_VOICE_INSTRUCT=Clear, natural voice with medium pitch
# Supported languages: Auto, Chinese, English, Japanese, Korean, German, French, Russian, Portuguese, Spanish, Italian
QWEN_LANGUAGE=Auto
# Device configuration (cuda:0 for ROCm GPU, cpu for CPU)
QWEN_DEVICE=cuda:0
# Data type options:
#   bfloat16 - Good balance, often fastest on AMD GPUs
#   float16 - May be slower on some GPUs
#   float32 - Slowest, most accurate
#   int8 or 8bit - 8-bit quantization (faster, less VRAM, slightly lower quality)
#   int4 or 4bit - 4-bit quantization (fastest, least VRAM, lower quality)
QWEN_DTYPE=bfloat16
# Flash attention optimization (true/false) - attempts to use flash-attn if available
QWEN_FLASH_ATTENTION=true
# Audio streaming chunk size (samples per chunk)
QWEN_SAMPLES_PER_CHUNK=1024
# Enable debug logging
QWEN_DEBUG=false

# Hugging Face Token (required for gated models)
# Get your token from https://huggingface.co/settings/tokens
HF_TOKEN=your_hf_token_here

# Chatterbox Turbo TTS Configuration
# High-quality real-time TTS (sub-200ms latency)
# Device configuration (cuda:0 for ROCm GPU, cpu for CPU)
CHATTERBOX_DEVICE=cuda:0
# Audio streaming chunk size (samples per chunk)
CHATTERBOX_SAMPLES_PER_CHUNK=1024
# Enable debug logging
CHATTERBOX_DEBUG=false

# Pocket TTS Configuration
# Ultra-low latency TTS (~200ms to first audio chunk)
# CPU-only model - GPU provides no speedup
# Built-in voice options (no HF token required):
#   alba, marius, javert, jean, fantine, cosette, eponine, azelma
# For voice cloning (requires accepting terms at https://huggingface.co/kyutai/pocket-tts):
#   Use HF URLs like: hf://kyutai/tts-voices/alba-mackenna/casual.wav
#   Or local .wav file paths
POCKET_VOICE=fantine
# Enable debug logging
POCKET_DEBUG=false
